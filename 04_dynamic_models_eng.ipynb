{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# 1. Data Preparation\n",
    "def load_and_preprocess_data(file_path=\"df_data_prepared.csv\", time_column=\"date\", target_column=\"pm2_5\", feature_cols=None):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Loaded {len(df)} rows from {file_path}\")\n",
    "    df[time_column] = pd.to_datetime(df[time_column])\n",
    "\n",
    "    # Add computed features\n",
    "    df['hour'] = df[time_column].dt.hour\n",
    "    df['season'] = (df[time_column].dt.month % 12 // 3).astype(int)\n",
    "\n",
    "    # Create full hourly range\n",
    "    full_time_range = pd.date_range(start=df[time_column].min(), end=df[time_column].max(), freq=\"h\")\n",
    "    df_full = df.set_index(time_column).reindex(full_time_range).reset_index().rename(columns={\"index\": time_column})\n",
    "\n",
    "    if feature_cols is None:\n",
    "        numeric_cols = [target_column]\n",
    "    else:\n",
    "        numeric_cols = [target_column] + feature_cols\n",
    "\n",
    "    numeric_cols = [col for col in numeric_cols if col in df_full.columns]\n",
    "    print(f\"Using features: {numeric_cols}\")\n",
    "\n",
    "    df_cleaned = df_full[numeric_cols].dropna()\n",
    "    print(f\"Removed {len(df_full) - len(df_cleaned)} rows with NaN in any numeric column for training\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(df_cleaned)\n",
    "\n",
    "    return df_full, data_scaled, scaler, numeric_cols\n",
    "\n",
    "# 2. Sequence Creation\n",
    "def create_seq2seq_data(data_scaled, pre_context_length, gap_length, post_context_length, feature_cols):\n",
    "    \"\"\"\n",
    "    Create sequences for Seq2Seq model training.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_scaled: Scaled data array\n",
    "    - pre_context_length: Length of pre-gap context\n",
    "    - gap_length: Length of the gap to predict\n",
    "    - post_context_length: Length of post-gap context\n",
    "    - feature_cols: Indices of features to use\n",
    "    \n",
    "    Returns:\n",
    "    - X_left: Pre-gap sequences\n",
    "    - X_right: Post-gap sequences\n",
    "    - y: Gap sequences (target)\n",
    "    \"\"\"\n",
    "    X_left, X_right, y = [], [], []\n",
    "    max_start = len(data_scaled) - pre_context_length - gap_length - post_context_length\n",
    "    for i in range(max_start):\n",
    "        left = data_scaled[i:i + pre_context_length, feature_cols]\n",
    "        right = data_scaled[i + pre_context_length + gap_length:i + pre_context_length + gap_length + post_context_length, feature_cols]\n",
    "        gap = data_scaled[i + pre_context_length:i + pre_context_length + gap_length, 0].reshape(-1, 1)  # Target (pm2_5 only)\n",
    "        X_left.append(left)\n",
    "        X_right.append(right)\n",
    "        y.append(gap)\n",
    "    return np.array(X_left), np.array(X_right), np.array(y)\n",
    "\n",
    "# 3. Time-Based Split\n",
    "def time_based_split_3(X_left, X_right, y, train_size=0.8):\n",
    "    \"\"\"\n",
    "    Split data into training and testing sets based on time.\n",
    "    \n",
    "    Returns:\n",
    "    - Training and testing sets for X_left, X_right, and y\n",
    "    \"\"\"\n",
    "    n_samples = len(y)\n",
    "    split_idx = int(n_samples * train_size)\n",
    "    X_left_train, X_left_test = X_left[:split_idx], X_left[split_idx:]\n",
    "    X_right_train, X_right_test = X_right[:split_idx], X_right[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    return X_left_train, X_left_test, X_right_train, X_right_test, y_train, y_test\n",
    "\n",
    "# 4. Synthetic Gaps\n",
    "def introduce_synthetic_gaps(df, target_col, missing_fraction, gap_length, random_state=None, max_index=None):\n",
    "    df_copy = df.copy()\n",
    "    n_samples = len(df_copy) if max_index is None else min(len(df_copy), max_index)\n",
    "    n_gaps = int(n_samples * missing_fraction / gap_length)\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    gap_starts = np.random.choice(n_samples - gap_length, n_gaps, replace=False)\n",
    "    gap_indices = []\n",
    "    for start in gap_starts:\n",
    "        df_copy.loc[start:start + gap_length - 1, target_col] = np.nan\n",
    "        gap_indices.extend(range(start, start + gap_length))\n",
    "    return df_copy, gap_indices, gap_starts\n",
    "\n",
    "# 5. Model Evaluation\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using multiple metrics.\n",
    "    \n",
    "    Returns:\n",
    "    - MAE, RMSE, R², MAPE\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100\n",
    "    return mae, rmse, r2, mape\n",
    "\n",
    "# 6. Training the Model\n",
    "def create_and_train_dynamic_seq2seq_xgb(X_left_train, y_train, X_right_train, pre_context_length, gap_lengths, feature_cols):\n",
    "    \"\"\"\n",
    "    Train a dynamic Seq2Seq model using XGBRegressor.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_left_train, X_right_train, y_train: Training data per gap length\n",
    "    - pre_context_length: Pre-gap context length\n",
    "    - gap_lengths: List of gap lengths to train on\n",
    "    - feature_cols: Feature indices\n",
    "    \n",
    "    Returns:\n",
    "    - Trained MultiOutputRegressor model\n",
    "    \"\"\"\n",
    "    C_max = 32\n",
    "    max_gap_length = max(gap_lengths)\n",
    "    n_features = len(feature_cols)\n",
    "\n",
    "    def prepare_data(X_left, X_right, y, gap_length):\n",
    "        C_dynamic = min(gap_length * 3 if gap_length <= 10 else 32, pre_context_length)\n",
    "        X_combined = []\n",
    "        y_padded_list = []\n",
    "        for i in range(len(X_left)):\n",
    "            left = X_left[i][-C_dynamic:, feature_cols]\n",
    "            right = X_right[i][:C_dynamic, feature_cols]\n",
    "            left_padded = np.pad(left, ((C_max - C_dynamic, 0), (0, 0)), mode='constant', constant_values=0)\n",
    "            right_padded = np.pad(right, ((0, C_max - C_dynamic), (0, 0)), mode='constant', constant_values=0)\n",
    "            left_flat = left_padded.flatten()\n",
    "            right_flat = right_padded.flatten()\n",
    "            metadata = np.array([gap_length, C_dynamic, i % gap_length])\n",
    "            combined = np.concatenate([left_flat, right_flat, metadata])\n",
    "            y_current = y[i].ravel()\n",
    "            if np.any(np.isnan(y_current)):\n",
    "                continue\n",
    "            y_padded = np.pad(y_current, (0, max_gap_length - len(y_current)), mode='constant', constant_values=0)\n",
    "            X_combined.append(combined)\n",
    "            y_padded_list.append(y_padded)\n",
    "        if not X_combined or not y_padded_list:\n",
    "            raise ValueError(\"No valid data after filtering NaN values\")\n",
    "        return np.array(X_combined), np.array(y_padded_list)\n",
    "\n",
    "    X_train_combined = []\n",
    "    y_train_padded = []\n",
    "    for gap_length in gap_lengths:\n",
    "        X_temp, y_temp = prepare_data(X_left_train[gap_length], X_right_train[gap_length], y_train[gap_length], gap_length)\n",
    "        X_train_combined.append(X_temp)\n",
    "        y_train_padded.append(y_temp)\n",
    "\n",
    "    X_train_combined = np.vstack(X_train_combined)\n",
    "    y_train_padded = np.vstack(y_train_padded)\n",
    "\n",
    "    model = MultiOutputRegressor(XGBRegressor(n_estimators=50, random_state=42))\n",
    "    model.fit(X_train_combined, y_train_padded)\n",
    "    return model\n",
    "\n",
    "# 7. Forecasting\n",
    "def direct_dynamic_seq2seq_forecast_xgb(model, initial_context, gap_length, pre_context_length, post_context_length, feature_cols):\n",
    "    \"\"\"\n",
    "    Forecast a gap using the trained model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained MultiOutputRegressor model\n",
    "    - initial_context: Context data around the gap (scaled)\n",
    "    - gap_length: Length of the gap to predict\n",
    "    - pre_context_length: Length of context before the gap\n",
    "    - post_context_length: Length of context after the gap\n",
    "    - feature_cols: List of feature indices to use (None for univariate)\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted gap values (scaled)\n",
    "    \"\"\"\n",
    "    C_dynamic = min(gap_length * 3 if gap_length <= 10 else 32, pre_context_length)\n",
    "    C_max = 32\n",
    "    \n",
    "    # Determine the number of features\n",
    "    if feature_cols is None:\n",
    "        # For univariate, use all columns in initial_context (should be just pm2_5)\n",
    "        n_features = initial_context.shape[1]\n",
    "        left_context = initial_context[:pre_context_length][-C_dynamic:]\n",
    "        right_context = initial_context[-post_context_length:][:C_dynamic]\n",
    "    else:\n",
    "        # For multivariate, use the specified feature indices\n",
    "        n_features = len(feature_cols)\n",
    "        left_context = initial_context[:pre_context_length, feature_cols][-C_dynamic:]\n",
    "        right_context = initial_context[-post_context_length:, feature_cols][:C_dynamic]\n",
    "\n",
    "    # Pad the contexts if necessary\n",
    "    left_padded = np.pad(left_context, ((C_max - C_dynamic, 0), (0, 0)), mode='constant', constant_values=0)\n",
    "    right_padded = np.pad(right_context, ((0, C_max - C_dynamic), (0, 0)), mode='constant', constant_values=0)\n",
    "    left_flat = left_padded.flatten()\n",
    "    right_flat = right_padded.flatten()\n",
    "    metadata = np.array([gap_length, C_dynamic, 0])\n",
    "    input_flat = np.concatenate([left_flat, right_flat, metadata]).reshape(1, -1)\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_flat)\n",
    "    return prediction[0, :gap_length].reshape(-1, 1)\n",
    "\n",
    "# 8. Testing Synthetic Gaps\n",
    "def test_synthetic_gaps(model, df, data_scaled, gap_indices, gap_starts, gap_length, scaler, pre_context_length, post_context_length, feature_cols):\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    max_index = data_scaled.shape[0]\n",
    "    \n",
    "    for start in gap_starts:\n",
    "        # Skip gaps that are out of bounds for data_scaled\n",
    "        if start + gap_length > max_index:\n",
    "            continue\n",
    "        \n",
    "        end = start + gap_length\n",
    "        context_start = max(0, start - pre_context_length)\n",
    "        context_end = min(max_index, end + post_context_length)\n",
    "        context = data_scaled[context_start:context_end, feature_cols]\n",
    "        \n",
    "        required_length = pre_context_length + post_context_length\n",
    "        if len(context) < required_length:\n",
    "            if len(context) == 0:\n",
    "                context = np.zeros((required_length, len(feature_cols)))\n",
    "            else:\n",
    "                context = np.pad(context, ((0, required_length - len(context)), (0, 0)), mode='constant', constant_values=0)\n",
    "        \n",
    "        pred = direct_dynamic_seq2seq_forecast_xgb(model, context, gap_length, pre_context_length, post_context_length, feature_cols)\n",
    "        true = data_scaled[start:end, 0].reshape(-1, 1)\n",
    "        \n",
    "        # Skip if true contains NaN values\n",
    "        if np.any(np.isnan(true)):\n",
    "            continue\n",
    "        \n",
    "        all_true.append(true)\n",
    "        all_pred.append(pred)\n",
    "    \n",
    "    if not all_true or not all_pred:\n",
    "        raise ValueError(\"No valid gaps to evaluate after filtering.\")\n",
    "    \n",
    "    all_true = np.concatenate(all_true)\n",
    "    all_pred = np.concatenate(all_pred)\n",
    "    \n",
    "    full_true_array = np.full((len(all_true), len(feature_cols)), np.nan)\n",
    "    full_pred_array = np.full((len(all_pred), len(feature_cols)), np.nan)\n",
    "    full_true_array[:, 0] = all_true.ravel()\n",
    "    full_pred_array[:, 0] = all_pred.ravel()\n",
    "    \n",
    "    all_true_unscaled = scaler.inverse_transform(full_true_array)\n",
    "    all_pred_unscaled = scaler.inverse_transform(full_pred_array)\n",
    "    \n",
    "    return all_true_unscaled[:, 0].ravel(), all_pred_unscaled[:, 0].ravel()\n",
    "\n",
    "# 9. Tester Class\n",
    "class DynamicSeq2SeqXGBTester:\n",
    "    def __init__(self, df, data_scaled, scaler, feature_cols, pre_context_length=32, post_context_length=32):\n",
    "        \"\"\"Initialize the tester with data and parameters.\"\"\"\n",
    "        self.df = df\n",
    "        self.data_scaled = data_scaled\n",
    "        self.scaler = scaler\n",
    "        self.feature_cols = feature_cols\n",
    "        self.pre_context_length = pre_context_length\n",
    "        self.post_context_length = post_context_length\n",
    "        self.results = {}\n",
    "        self.predictions = {}\n",
    "\n",
    "    def prepare_data(self, gap_lengths):\n",
    "        \"\"\"Prepare data for each gap length.\"\"\"\n",
    "        data_per_gap = {}\n",
    "        for gap_length in gap_lengths:\n",
    "            X_left, X_right, y = create_seq2seq_data(\n",
    "                self.data_scaled, self.pre_context_length, gap_length, self.post_context_length, self.feature_cols\n",
    "            )\n",
    "            X_left_train, X_left_test, X_right_train, X_right_test, y_train, y_test = time_based_split_3(X_left, X_right, y)\n",
    "            data_per_gap[gap_length] = (X_left_train, X_right_train, y_train, X_left_test, X_right_test, y_test)\n",
    "        return data_per_gap\n",
    "\n",
    "    def run_tests(self, gap_lengths=[5, 12, 24, 48, 72], n_runs=10, missing_fraction=0.05, model_save_path=\"dynamic_seq2seq_xgb_model.joblib\"):\n",
    "        data_per_gap = self.prepare_data(gap_lengths)\n",
    "\n",
    "        print(\"Training DynamicSeq2SeqXGB on all gap lengths...\")\n",
    "        start_time = time.time()\n",
    "        X_left_train = {gl: data_per_gap[gl][0] for gl in gap_lengths}\n",
    "        X_right_train = {gl: data_per_gap[gl][1] for gl in gap_lengths}\n",
    "        y_train = {gl: data_per_gap[gl][2] for gl in gap_lengths}\n",
    "        model = create_and_train_dynamic_seq2seq_xgb(X_left_train, y_train, X_right_train, self.pre_context_length, gap_lengths, self.feature_cols)\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "        joblib.dump(model, model_save_path)\n",
    "        print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "        for gap_length in gap_lengths:\n",
    "            self.results[gap_length] = {}\n",
    "            self.predictions[gap_length] = {}\n",
    "            print(f\"Testing on gap length {gap_length}...\")\n",
    "            metrics_runs = []\n",
    "            all_true_runs = []\n",
    "            all_pred_runs = []\n",
    "            run_times = []\n",
    "\n",
    "            for run in range(n_runs):\n",
    "                run_start_time = time.time()\n",
    "                df_missing, gap_indices, gap_starts = introduce_synthetic_gaps(\n",
    "                    self.df, \"pm2_5\", missing_fraction, gap_length, random_state=run, max_index=len(self.data_scaled)\n",
    "                )\n",
    "                all_true, all_pred = test_synthetic_gaps(\n",
    "                    model, self.df, self.data_scaled, gap_indices, gap_starts, gap_length, self.scaler,\n",
    "                    self.pre_context_length, self.post_context_length, self.feature_cols\n",
    "                )\n",
    "                metrics = evaluate_model(all_true, all_pred)\n",
    "                metrics_runs.append(metrics)\n",
    "                all_true_runs.append(all_true)\n",
    "                all_pred_runs.append(all_pred)\n",
    "                run_times.append(time.time() - run_start_time)\n",
    "\n",
    "            metrics_array = np.array(metrics_runs)\n",
    "            self.results[gap_length] = {\n",
    "                \"MAE\": {\"mean\": np.mean(metrics_array[:, 0]), \"std\": np.std(metrics_array[:, 0])},\n",
    "                \"RMSE\": {\"mean\": np.mean(metrics_array[:, 1]), \"std\": np.std(metrics_array[:, 1])},\n",
    "                \"R2\": {\"mean\": np.mean(metrics_array[:, 2]), \"std\": np.std(metrics_array[:, 2])},\n",
    "                \"MAPE\": {\"mean\": np.mean(metrics_array[:, 3]), \"std\": np.std(metrics_array[:, 3])},\n",
    "                \"run_times\": run_times,\n",
    "                \"total_time\": sum(run_times)\n",
    "            }\n",
    "            self.predictions[gap_length] = {\n",
    "                \"all_true\": np.concatenate(all_true_runs),\n",
    "                \"all_pred\": np.concatenate(all_pred_runs)\n",
    "            }\n",
    "            print(f\"Finished testing on gap length {gap_length} in {sum(run_times):.2f} seconds\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    def summarize_results(self, visualize=True, output_dir=\"plots_dynamic\"):\n",
    "        \"\"\"Summarize and optionally visualize results.\"\"\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        for gap_length in self.results:\n",
    "            print(f\"\\nResults for gap length {gap_length}:\")\n",
    "            for metric in [\"MAE\", \"RMSE\", \"R2\", \"MAPE\"]:\n",
    "                mean = self.results[gap_length][metric][\"mean\"]\n",
    "                std = self.results[gap_length][metric][\"std\"]\n",
    "                print(f\"{metric}: {mean:.4f} ± {std:.4f}\")\n",
    "            print(f\"Total time: {self.results[gap_length]['total_time']:.2f} seconds\")\n",
    "\n",
    "            if visualize:\n",
    "                all_true = self.predictions[gap_length][\"all_true\"]\n",
    "                all_pred = self.predictions[gap_length][\"all_pred\"]\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.scatter(all_true, all_pred, alpha=0.5)\n",
    "                min_val, max_val = min(all_true.min(), all_pred.min()), max(all_true.max(), all_pred.max())\n",
    "                plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "                plt.xlabel(\"True Values (µg/m³)\")\n",
    "                plt.ylabel(\"Predicted Values (µg/m³)\")\n",
    "                plt.title(f\"DynamicSeq2SeqXGB: True vs Predicted (Gap Length = {gap_length})\")\n",
    "                plt.savefig(os.path.join(output_dir, f\"scatter_gap_{gap_length}.png\"), dpi=600)\n",
    "                plt.close()\n",
    "\n",
    "# 10. Filling Real Gaps\n",
    "def fill_real_gaps(df, model_path=\"dynamic_seq2seq_xgb_model.joblib\", scaler=None, pre_context_length=32, post_context_length=32, column=\"pm2_5\", max_gap_length=72, feature_names=None, feature_indices=None):\n",
    "    \"\"\"\n",
    "    Fill real gaps in the data using the trained model.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with missing values\n",
    "    - model_path: Path to the trained model\n",
    "    - scaler: Fitted StandardScaler object\n",
    "    - pre_context_length: Length of context before the gap\n",
    "    - post_context_length: Length of context after the gap\n",
    "    - column: Target column to fill (e.g., 'pm2_5')\n",
    "    - max_gap_length: Maximum gap length the model can handle\n",
    "    - feature_names: List of feature column names for df (None for univariate)\n",
    "    - feature_indices: List of feature indices for data_scaled (None for univariate)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with filled gaps\n",
    "    \"\"\"\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "    df_filled = df.copy()\n",
    "    df_filled['hour'] = df_filled['date'].dt.hour\n",
    "    df_filled['season'] = (df_filled['date'].dt.month % 12 // 3).astype(int)\n",
    "    numeric_cols = ['pm2_5'] if feature_names is None else ['pm2_5'] + feature_names\n",
    "    data_scaled = scaler.transform(df_filled[numeric_cols])\n",
    "\n",
    "    nan_indices = df.index[df[column].isna()].tolist()\n",
    "    if not nan_indices:\n",
    "        print(\"No missing values found in the data.\")\n",
    "        return df_filled\n",
    "\n",
    "    gap_starts = []\n",
    "    gap_lengths = []\n",
    "    current_start = nan_indices[0]\n",
    "    current_length = 1\n",
    "\n",
    "    for i in range(1, len(nan_indices)):\n",
    "        if nan_indices[i] == nan_indices[i-1] + 1:\n",
    "            current_length += 1\n",
    "        else:\n",
    "            gap_starts.append(current_start)\n",
    "            gap_lengths.append(current_length)\n",
    "            current_start = nan_indices[i]\n",
    "            current_length = 1\n",
    "    gap_starts.append(current_start)\n",
    "    gap_lengths.append(current_length)\n",
    "\n",
    "    # Determine the number of features based on numeric_cols\n",
    "    n_features = len(numeric_cols)\n",
    "\n",
    "    for start, gap_length in zip(gap_starts, gap_lengths):\n",
    "        position_start = df.index.get_loc(start)\n",
    "        print(f\"Processing gap at index {start} with length {gap_length}\")\n",
    "\n",
    "        if gap_length > max_gap_length:\n",
    "            num_full_chunks = gap_length // max_gap_length\n",
    "            remainder = gap_length % max_gap_length\n",
    "            all_pred_unscaled = []\n",
    "\n",
    "            for chunk in range(num_full_chunks):\n",
    "                chunk_start_idx = position_start + chunk * max_gap_length\n",
    "                context_start = max(0, chunk_start_idx - pre_context_length)\n",
    "                context_end = min(len(data_scaled), chunk_start_idx + max_gap_length + post_context_length)\n",
    "                context = data_scaled[context_start:context_end]\n",
    "                if feature_indices is not None:\n",
    "                    context = context[:, feature_indices]\n",
    "                if len(context) < pre_context_length + post_context_length:\n",
    "                    if len(context) == 0:\n",
    "                        context = np.zeros((pre_context_length + post_context_length, n_features))\n",
    "                    else:\n",
    "                        context = np.pad(context, ((0, pre_context_length + post_context_length - len(context)), (0, 0)), mode='constant', constant_values=0)\n",
    "                pred_scaled = direct_dynamic_seq2seq_forecast_xgb(model, context, max_gap_length, pre_context_length, post_context_length, feature_indices)\n",
    "                full_pred_array = np.full((len(pred_scaled), n_features), np.nan)\n",
    "                full_pred_array[:, 0] = pred_scaled.ravel()\n",
    "                pred_unscaled = scaler.inverse_transform(full_pred_array)\n",
    "                all_pred_unscaled.append(pred_unscaled[:, 0].ravel())\n",
    "\n",
    "            if remainder > 0:\n",
    "                chunk_start_idx = position_start + num_full_chunks * max_gap_length\n",
    "                context_start = max(0, chunk_start_idx - pre_context_length)\n",
    "                context_end = min(len(data_scaled), chunk_start_idx + remainder + post_context_length)\n",
    "                context = data_scaled[context_start:context_end]\n",
    "                if feature_indices is not None:\n",
    "                    context = context[:, feature_indices]\n",
    "                if len(context) < pre_context_length + post_context_length:\n",
    "                    if len(context) == 0:\n",
    "                        context = np.zeros((pre_context_length + post_context_length, n_features))\n",
    "                    else:\n",
    "                        context = np.pad(context, ((0, pre_context_length + post_context_length - len(context)), (0, 0)), mode='constant', constant_values=0)\n",
    "                pred_scaled = direct_dynamic_seq2seq_forecast_xgb(model, context, remainder, pre_context_length, post_context_length, feature_indices)\n",
    "                full_pred_array = np.full((len(pred_scaled), n_features), np.nan)\n",
    "                full_pred_array[:, 0] = pred_scaled.ravel()\n",
    "                pred_unscaled = scaler.inverse_transform(full_pred_array)\n",
    "                all_pred_unscaled.append(pred_unscaled[:, 0].ravel())\n",
    "\n",
    "            pred_unscaled_full = np.concatenate(all_pred_unscaled)\n",
    "        else:\n",
    "            context_start = max(0, position_start - pre_context_length)\n",
    "            context_end = min(len(data_scaled), position_start + gap_length + post_context_length)\n",
    "            context = data_scaled[context_start:context_end]\n",
    "            if feature_indices is not None:\n",
    "                context = context[:, feature_indices]\n",
    "            if len(context) < pre_context_length + post_context_length:\n",
    "                if len(context) == 0:\n",
    "                    context = np.zeros((pre_context_length + post_context_length, n_features))\n",
    "                else:\n",
    "                    context = np.pad(context, ((0, pre_context_length + post_context_length - len(context)), (0, 0)), mode='constant', constant_values=0)\n",
    "            pred_scaled = direct_dynamic_seq2seq_forecast_xgb(model, context, gap_length, pre_context_length, post_context_length, feature_indices)\n",
    "            full_pred_array = np.full((len(pred_scaled), n_features), np.nan)\n",
    "            full_pred_array[:, 0] = pred_scaled.ravel()\n",
    "            pred_unscaled = scaler.inverse_transform(full_pred_array)\n",
    "            pred_unscaled_full = pred_unscaled[:, 0].ravel()\n",
    "\n",
    "        gap_indices = df.index[position_start:position_start + gap_length]\n",
    "        df_filled.loc[gap_indices, column] = pred_unscaled_full\n",
    "\n",
    "    print(f\"Filled {len(nan_indices)} missing values in {len(gap_starts)} gaps.\")\n",
    "    return df_filled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Define feature columns for multivariate model\n",
    "    multi_feature_cols = ['Ff', 'DD', 'air_temperature', 'air_humidity', 'hour', 'season']\n",
    "\n",
    "    # Univariate model\n",
    "    print(\"\\n=== Univariate Model ===\")\n",
    "    df_full_uni, data_scaled_uni, scaler_uni, numeric_cols_uni = load_and_preprocess_data(\"df_data_prepared.csv\", feature_cols=None)\n",
    "    tester_uni = DynamicSeq2SeqXGBTester(df_full_uni, data_scaled_uni, scaler_uni, feature_cols=[0])  # feature_cols as indices for data_scaled\n",
    "    model_uni = tester_uni.run_tests(gap_lengths=[5, 12, 24, 48, 72], n_runs=10, model_save_path=\"dynamic_uniseq2seq_xgb_model.joblib\")\n",
    "    tester_uni.summarize_results(visualize=True, output_dir=\"plots_dynamic_uni\")\n",
    "\n",
    "    # Multivariate model\n",
    "    print(\"\\n=== Multivariate Model ===\")\n",
    "    df_full_multi, data_scaled_multi, scaler_multi, numeric_cols_multi = load_and_preprocess_data(\"df_data_prepared.csv\", feature_cols=multi_feature_cols)\n",
    "    feature_indices = list(range(len(numeric_cols_multi)))  # Indices for data_scaled\n",
    "    tester_multi = DynamicSeq2SeqXGBTester(df_full_multi, data_scaled_multi, scaler_multi, feature_cols=feature_indices)\n",
    "    model_multi = tester_multi.run_tests(gap_lengths=[5, 12, 24, 48, 72], n_runs=10, model_save_path=\"dynamic_multiseq2seq_xgb_model.joblib\")\n",
    "    tester_multi.summarize_results(visualize=True, output_dir=\"plots_dynamic_multi\")\n",
    "\n",
    "    # Filling real gaps\n",
    "    df_with_nans = pd.read_csv(\"df_data_prepared.csv\")\n",
    "    df_with_nans[\"date\"] = pd.to_datetime(df_with_nans[\"date\"])\n",
    "    full_time_range = pd.date_range(start=df_with_nans[\"date\"].min(), end=df_with_nans[\"date\"].max(), freq=\"h\")\n",
    "    df_with_nans_full = df_with_nans.set_index(\"date\").reindex(full_time_range).reset_index().rename(columns={\"index\": \"date\"})\n",
    "\n",
    "    # Univariate gap filling\n",
    "    print(\"\\n=== Filling Real Gaps (Univariate) ===\")\n",
    "    df_filled_uni = fill_real_gaps(\n",
    "        df_with_nans_full,\n",
    "        model_path=\"dynamic_uniseq2seq_xgb_model.joblib\",\n",
    "        scaler=scaler_uni,\n",
    "        feature_names=None,  # No additional feature names for univariate\n",
    "        feature_indices=None  # No feature indices for univariate\n",
    "    )\n",
    "    df_filled_uni.to_csv(\"df_data_filled_uni.csv\", index=False)\n",
    "    print(\"Univariate filled data saved to 'df_data_filled_uni.csv'\")\n",
    "\n",
    "    # Multivariate gap filling\n",
    "    print(\"\\n=== Filling Real Gaps (Multivariate) ===\")\n",
    "    df_filled_multi = fill_real_gaps(\n",
    "        df_with_nans_full,\n",
    "        model_path=\"dynamic_multiseq2seq_xgb_model.joblib\",\n",
    "        scaler=scaler_multi,\n",
    "        feature_names=multi_feature_cols,  # Column names for df_filled\n",
    "        feature_indices=feature_indices  # Indices for data_scaled\n",
    "    )\n",
    "    df_filled_multi.to_csv(\"df_data_filled_multi.csv\", index=False)\n",
    "    print(\"Multivariate filled data saved to 'df_data_filled_multi.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# MAE data from the results table\n",
    "gap_lengths = [5, 12, 24, 48, 72]\n",
    "uni_mae = [8.287, 7.978, 8.790, 9.676, 11.651]\n",
    "multi_mae = [7.665, 7.253, 7.868, 8.025, 10.772]\n",
    "uni_mae_std = [1.549, 2.015, 1.844, 4.557, 4.611]\n",
    "multi_mae_std = [1.521, 1.800, 2.677, 3.708, 6.214]\n",
    "\n",
    "# Calculate percentage reduction\n",
    "reduction = [(uni - multi) / uni * 100 for uni, multi in zip(uni_mae, multi_mae)]\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(gap_lengths)) * 1.1  # Increased interval between groups\n",
    "\n",
    "# Create bar groups\n",
    "bars1 = ax.bar([i - 0.15 for i in index], uni_mae, bar_width, label='Dynamic Univariate', \n",
    "               color='steelblue', yerr=uni_mae_std, capsize=3, ecolor=\"gray\")\n",
    "bars2 = ax.bar([i + 0.15 for i in index], multi_mae, bar_width, label='Dynamic Multivariate', \n",
    "               color='forestgreen', yerr=multi_mae_std, capsize=3, ecolor=\"gray\")\n",
    "\n",
    "# Add MAE reduction percentages\n",
    "z = [0, 1.1, 2.2, 3.3, 4.4]  # Adjusted positions for the text\n",
    "for i, pct in enumerate(reduction):\n",
    "    ax.text(z[i], max(uni_mae[i], multi_mae[i]) + 1, f'▼ {pct:.1f}%', \n",
    "            ha='center', va='bottom')\n",
    "\n",
    "# Plot formatting\n",
    "ax.set_xlabel('Gap Length (hours)', fontsize=12)\n",
    "ax.set_ylabel('MAE (µg/m³)', fontsize=12)\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(gap_lengths)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "# Grid for better readability\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(\"output_diagrams\", 'dynamic_models_comparison.png'), dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env_new (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}